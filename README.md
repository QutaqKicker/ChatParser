# ChatParser

Это кластер микросервисов, у которого есть лишь одно полезное применение: перевести HTML/JSON дамп сообщений из какой-нибудь беседы в Telegram в локальную базу данных.

Далее эти сообщения можно будет бэкапнуть в выгрузку в формате CSV/Parquet, и при желании снова отправить их в БД (хотя БД их выплюнет из-за коллизии ключей). Такой несложный функционал я обернул в несколько микросервисов, жонглирующих Kafka. Все это только ради практики.

Этот проект еще далек от завершения, нужно много чего отрефакторить, покрыть тестами и комментариями, чем я и занимаюсь в свободное время. Предлагаю не судить автора исключительно по ошибкам в этом сыром проекте.

## Установка и запуск

Для запуска потребуется **Taskfile**. Для запуска контуров Kafka, БД, установки переменных окружения и пуска миграций нужно выполнить:
task runAll
А сами сервисы пока вручную дергать придется, до такого деплоя пока руки не дотянулись.

## Описание сервисов

### Chat
Сервис для хранения сообщений, которые ему скормили соответствующей gRPC ручкой. Имеет ручки для отдачи и удаления сообщений. В перспективе это все будет дергаться через сервис клиента.

Скормить можно HTML/JSON дампы сообщений из Telegram или дампы CSV/Parquet, сгенерированные сервисом Backup. Сервис Chat сам посмотрит на расширения в директории и разберется, какой парсинг запускать.

При парсинге подсчитывает количество сообщений по каждому пользователю и отправляет все это в топик Kafka для сервиса User. Особого смысла тут нет, просто ради того, чтобы подергать Kafka на Go.

**Логгер**, кстати, отправляет все логи по Kafka в сервис Audit.

### User
Сервис для хранения количества хранимых сообщений для каждого клиента. Получает все это по Kafka при парсинге. Имеет ручку для отдачи количества сообщений. В перспективе это будет дергать клиент.

### Audit
Сервис для хранения логов со всех сервисов. Получает все это добро по Kafka и сохраняет в БД.

### Backup (еще не проверен)
Сервис, который имеющиеся в сервисе Chat сообщения выгружает в CSV или Parquet файлы. У него есть gRPC ручки, инициирующие этот процесс. Сообщения из сервиса берет батчами, батчи грузит в разные файлы параллельно.

Хотя Parquet надо бы в один файл грузить в разные RowGroups.

### Client (Еще не сделан)
Планируется как консольное приложение, дергающее REST ручки от сервиса Router. Предполагается запрос сообщений, количество сообщений по пользователям, запрос на парс сообщений из дампов и бэкап имеющихся сообщений.

### Router (Еще не сделан)
Будет принимать REST запросы от клиента и в соответствии с ними слать остальным сервисам RPC запросы.

## Остальные составляющие

### Protos
Здесь хранятся протофайлы и Go файлы, сгенерированные в соответствии с ними. `common.proto` нужен для использования одной и той же модели в двух разных протофайлах.

### Common
Здесь хранится общая логика, константы, контракты, которые используются остальными сервисами.

По логике, стоит выделить:
- **myKafka:** Здесь хранится логика для консюмеров и продюсеров Kafka.
- **dbHelper:** Это построитель SQL-запросов. Благодаря нему в проектах не приходится писать SQL-запросы. Не сказал бы, что это удобнее, не очень руки чесались попробовать написать свою ORM на Go.

### db-init-script
Тут хранится инициирующий скрипт, который прогоняется при инициации контейнера PostgreSQL. Там создаются БД под сервисы.
